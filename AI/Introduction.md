# Week 1 â€“ Fundamentals of Artificial Intelligence  

## CSC462 â€“ Artificial Intelligence  

---

## ðŸ”¹ What is Artificial Intelligence?
- AI is the study of making machines **think and act intelligently**.  
- Four approaches:  
  - **Thinking Humanly**  
  - **Acting Humanly**  
  - **Thinking Rationally**  
  - **Acting Rationally**  
- AI aims to **mimic human intelligence** and decision-making.  

---

## ðŸ”¹ Weak AI vs Strong AI
- **Weak AI:** Focused on solving specific tasks (e.g., Chess AI, Siri).  
- **Strong AI:** Hypothetical; capable of **general intelligence** like humans.  
- Todayâ€™s AI is **mostly Weak AI**.  

---

## ðŸ”¹ AI Perspectives
- **Thinking Humanly:** Cognitive modeling.  
- **Acting Humanly:** Turing Test approach.  
- **Thinking Rationally:** Logic-based reasoning.  
- **Acting Rationally:** Rational agents maximizing performance.  

---

## ðŸ”¹ Applications of AI
- **Healthcare** â€“ diagnosis, drug discovery  
- **Finance** â€“ fraud detection, trading  
- **Transportation** â€“ self-driving cars  
- **Education** â€“ tutoring systems  
- **Entertainment** â€“ recommendation systems  

---

## ðŸ”¹ Challenges & Ethics in AI
- Ambiguity and uncertainty in real-world data  
- Bias in algorithms  
- Transparency and explainability  
- Automation and job loss  
- Security and misuse of AI  

---

## ðŸ”¹ Why Study AI?
- Automates tedious tasks  
- Solves complex real-world problems  
- Enhances human decision-making  
- Pushes the boundaries of technology  
- Essential foundation for **future computing**  

---

# Week 2 â€“ Intelligent Agents & Environments  
CSC462 â€“ Artificial Intelligence  

---

## ðŸ”¹ What is an Agent?  
- An **agent** perceives its **environment** through sensors and acts through **actuators**.  
- Core cycle: **Perception â†’ Decision â†’ Action**  

---

## ðŸ”¹ Examples of Agents  
- ðŸ¤– **Robot vacuum cleaner**  
  - Sensors: dirt detector  
  - Actuators: wheels  

- ðŸ’¬ **Chatbot**  
  - Sensors: user input  
  - Actuators: text reply  

---

## ðŸ”¹ PEAS Model  
To describe an agent:  
- **P** â€“ Performance measure  
- **E** â€“ Environment  
- **A** â€“ Actuators  
- **S** â€“ Sensors  

---

## ðŸ”¹ Types of Environments (1/3)  
- **Observable vs. Partially Observable**  
  - Fully observable: chess  
  - Partially observable: poker  

- **Deterministic vs. Stochastic**  
  - Deterministic: tic-tac-toe  
  - Stochastic: weather  

---

## ðŸ”¹ Types of Environments (2/3)  
- **Episodic vs. Sequential**  
  - Episodic: spam filtering  
  - Sequential: chess  

- **Static vs. Dynamic**  
  - Static: crossword puzzle  
  - Dynamic: driving  

---

## ðŸ”¹ Types of Environments (3/3)  
- **Discrete vs. Continuous**  
  - Discrete: board games  
  - Continuous: self-driving cars  

- **Single-Agent vs. Multi-Agent**  
  - Single: crossword solver  
  - Multi: football match  

- **Simple vs. Complex**  
  - Simple: tic-tac-toe  
  - Complex: stock market  

---

## ðŸ”¹ Task Environment  
- Defined by a combination of properties:  
  - observable, deterministic, episodic, etc.  
- Determines **agent design complexity**  

---

## ðŸ”¹ Rational Agent  
- A **rational agent** chooses the **best possible action** to maximize performance.  

---

## ðŸ”¹ Why Study Environments?  
- Helps design the **right type of agent** for the right problem.  

---


# Week 3 â€“ Types of Agents  
CSC462 â€“ Artificial Intelligence  

---

## ðŸ”¹ Simple Reflex Agents  
- Act only on **current perception** (no memory).  
- **Example:** Thermostat (turns on heater if temp < 20Â°C).  

**Limitations:**  
- Work well only in simple, fully observable environments.  
- Fail in complex or partially observable worlds.  

---

## ðŸ”¹ Model-Based Reflex Agents  
- Maintain an **internal model** of the world.  
- Handle **partial observability**.  

**Example:** Self-driving car tracking nearby vehicles.  

---

## ðŸ”¹ Goal-Based Agents  
- Choose actions to achieve **specific goals**.  
- **Example:** GPS navigation planning a route.  

**Advantage:** More flexible (long-term planning).  

---

## ðŸ”¹ Utility-Based Agents  
- Use a **utility function** to evaluate states.  
- **f(state) â†’ real number** (higher = better).  
- **Example:** Delivery robot choosing between shortest vs safest path.  

**Advantage:** Balances multiple goals.  

---

## ðŸ”¹ Learning Agents  
- Improve performance with **experience + feedback**.  
- **Example:** Spam filters adapting to new spam patterns.  

**Components:**  
1. Learning element  
2. Performance element  
3. Critic (feedback)  
4. Problem generator (exploration)  

---

## ðŸ”¹ Hierarchy of Agents  
Reflex < Model-Based < Goal-Based < Utility-Based < Learning  

---

## ðŸ”¹ Rationality in Agents  
- Each agent type can be **rational** if matched with the right environment.  

---

## ðŸ”¹ Trade-offs  
- Reflex â†’ simple, but inflexible  
- Goal-based â†’ flexible, but computationally heavy  
- Utility-based â†’ smarter, but needs utility definition  

---

## ðŸ”¹ Real-World Example: Self-Driving Car  
Combines multiple agent types:  
- Reflex â†’ emergency braking  
- Model-based â†’ track cars  
- Goal-based â†’ reach destination  
- Utility-based â†’ balance speed & safety  
- Learning â†’ adapt to driver behavior  

---

## ðŸ”¹ Key Takeaway  
ðŸ‘‰ Choosing the right type of agent depends on:  
- Environment complexity  
- Uncertainty  
- Agentâ€™s goals  

---

---

# Week 4 â€“ Search Concepts & BFS  
CSC462 â€“ Artificial Intelligence  

---

## ðŸ”¹ Problem-Solving in AI  
- Many AI tasks can be seen as **search problems**.  
- Goal: find a path from **start state â†’ goal state**.  

---

## ðŸ”¹ Problem Formulation  
Define a problem in terms of:  
- Initial state  
- Actions available  
- Transition model (results of actions)  
- Goal test (check if solved)  
- Path cost (evaluate solution)  

---

## ðŸ”¹ Search Space  
- Set of all possible states reachable from initial state.  

## ðŸ”¹ Search Algorithm  
- Explores the search space to find a solution path.  

---

## ðŸ”¹ Types of Search  
- **Uninformed Search** â†’ blind search (BFS, DFS, Uniform Cost)  
- **Informed Search** â†’ uses heuristics (A*, Greedy Best-First)  

---

# Breadth-First Search (BFS)  

---

## ðŸ”¹ BFS Concept  
- Explores all nodes at one depth before moving to the next.  

## ðŸ”¹ Implementation  
- Uses a **queue (FIFO)** to expand nodes in order.  

---

## ðŸ”¹ BFS Properties  
- **Completeness:** Guaranteed to find solution if one exists.  
- **Optimality:** Finds shortest path (if all costs equal).  

---

## ðŸ”¹ BFS Complexity  
- **Time Complexity:** O(b^d)  
  - b = branching factor  
  - d = depth of shallowest solution  

- **Space Complexity:** O(b^d)  
  - must store all nodes at current depth  

---

## ðŸ”¹ BFS â€“ Advantages  
- Finds shortest solution path  
- Simple to implement  

## ðŸ”¹ BFS â€“ Disadvantages  
- High memory usage for large search spaces  
- Slow if solution is deep  

---

# âœ… Key Point  
BFS is **complete & optimal** (when costs are equal) but requires **huge memory** for deep searches.  
